\vspace{-10pt}
\section{Introduction}\label{sec:introduction}

%introduction
Real-time systems differ from traditional computing systems in that one or more tasks must complete execution within a specified deadline, otherwise the utility of the result is severely diminished or utterly useless.  Ensuring real-time task systems meet their corresponding deadlines is the subject of prominent research on schedulability analysis.  Paramount to schedulability analysis is accurate characterization of WCET.  While the debate continues on whether non-preemptive versus fully preemptive execution is more effective, recent research on limited preemption models has shown to outperform non-preemptive scheduling approaches in terms of schedulability and the fully preemptive scheduling approach in terms of the number of preemptions when preemption cost is considered.  Non-preemptive execution has the disadvantage of introducing blocking of high priority tasks by lower priority tasks whereas fully preemptive execution has the disadvantage of significant preemption overhead which has shown to be up to 44\%~\cite{pellizzoni:07}~\cite{pellizzoni:08}~\cite{pellizzoni:11} of a tasks WCET.

One of the noticeable contributors to preemption overhead is due to cache related preemption delay (CRPD).  CRPD occurs when a task denoted \begin{math}\tau_{i}\end{math} is preempted by one or more higher priority tasks denoted \begin{math}\tau_{k}\end{math} whose execution results in the eviction of cache memory blocks that must be subsequently reloaded when task \begin{math}\tau_{i}\end{math} resumes execution.  Limited preemption approaches have the advantage of reduced blocking with a limited number of allowed preemptions while having the advantage of sections of non-preemptive regions (NPRs) reducing the preemption overhead.  One promising approach to implementing a limited preemption approach is selecting preemption points for each task subject to the constraint on maximum non-preemptive region execution time \begin{math}Q_{i}\end{math}.  A paper by Bertogna et. al.~\cite{bertogna:11} proposed and realized a quadratic time algorithm for selecting optimal preemption points for a linear basic block structure.  A linear basic block structure implies that conditional logic and branches are fully contained within basic block boundaries. CRPD literature permits basic blocks connected by arbitrary control flow graph structures.  The primary contributions outlined in this paper include improved accuracy for computing CRPD cost taking into account where preemptions actually occur, and a revised optimal preemption point placement algorithm implemented via dynamic programming using the more accurate CRPD cost.  Furthermore, we demonstrate using a case study improved task set schedulability and optimal preemption point placement as compared to state of the art methods.
%Figure~\ref{fig:system_model} illustrates the problem scope for selecting optimal preemption points for a linear basic block structure.

%outline of paper
The rest of this paper is organized as follows. First, current research efforts and related work in the areas of cache related preemption delay and limited preemption scheduling is discussed in Section~\ref{sec:related}.  Section~\ref{sec:system_model} describes the real-time task model terminology used in this paper.  The enhanced CRPD computation approach is detailed in Section~\ref{sec:crpd_computation}. Section~\ref{sec:schedulability_analysis} briefly outlines the integrated WCET/CRPD computation approach incorporated into fixed priority (FP) and earliest deadline first (EDF) schedulability analysis.  The enhanced limited preemption point placement algorithm leverages the improved WCET/CRPD computation in a quadratic time algorithm as discussed in Section~\ref{sec:implementation}.  A case study using well known bench mark tasks illustrating the benefits of our proposed method are presented and summarized in Section~\ref{sec:evaluation}.  Finally we will offer relevant conclusions along with proposed future work in Section~\ref{sec:conclusion}. 