%\vspace{-10pt}
\section{Related Work}\label{sec:related}

\subsection {CRPD Calculation}\label{sec:crpd_related_work}
Analyzing the preempted task, Lee et al.~\cite{lee:96}~\cite{lee:97}~\cite{lee:98} introduced the concept and algorithm for computing the set of useful cache blocks (UCB) for statically addressed instruction and data for direct mapped and set-associative caches.
%where dynamic memory accesses are treated as cache misses.
The UCBs of the preempted task are used to compute the CRPD, which is simply the cardinality of the UCB set times the cache block reload time (BRT).
\newline
\indent
Analyzing the preempting task, Tomiyamay and Dutt~\cite{tomiyamay:00} computed the set of evicting cache blocks (ECBs) via program path analysis formulating an integer linear programming model for direct mapped instruction caches.  The set of UCBs and ECBs can be computed using control flow graph (CFG) analysis of reaching memory blocks (RMB) and live memory blocks (LMB)~\cite{lee:96}~\cite{lee:97}~\cite{lee:98}.

In a similar fashion, the ECBs of the preempting task are used to compute the CRPD.
%which is again the cardinality of the ECB set times the cache block reload time (BRT).
Formal definitions of UCBs and ECBs were outlined by Altmeyer and Burguiere~\cite{altmeyer:11c}.  The preempting task’s memory accesses quantified as the set of evicting cache blocks will evict useful cache blocks thereby imposing non-negligible CRPD on the preempted task.

Complementary work by Negi et al.~\cite{negi:03} and Tan and Mooney~\cite{tan:04} compute the intersection of the ECB and UCB sets to achieve tighter bounds on the CRPD computation for direct-mapped and set-associative instruction caches.
%Negi`s work computes the set of UCBs and ECBs using the notion of reaching cache state and live cache state. This representation of the cache content enhances Lee`s original approach at the cost of higher computational complexity.
Staschulat and Ernst~\cite{staschulat:05c} realized an improvement in computational complexity at the expense of CRPD accuracy or tightness via a cache state reduction technique for direct mapped instruction caches that was later extended to address set-associative caches.
%This is accomplished by limiting the cache state size and selecting a revised cache state between two sets that minimizes the set difference.
One of the limitations with the existing UCB based analysis methods is their representation of memory blocks that may reside in cache memory.  This over-approximation was employed to realize a safe bounds on CRPD which is referred to as “may cache”~\cite{altmeyer:11c}.

Likewise, WCET analysis tools use an over-approximation to estimate cache misses and an under-approximation to estimate cache hits.  Cache hits are memory blocks that must reside in cache memory hence the term used to describe this set is “must cache”~\cite{altmeyer:11c}.  Altmeyer and Burguiere~\cite{altmeyer:11c} addressed this issue by introducing the notion of definitely-cached useful cache block (DC-UCB)~\cite{altmeyer:11c}.  The DC-UCB is useful in schedulability analysis to avoid double counting of cache misses resulting from intra-task cache block eviction.

Ramaprasad and Mueller~\cite{ramaprasad:06} examine the problem of dynamic addressing supporting CRPD analysis. Their algorithm employs memory access patterns to compute CRPD, instead of UCBs.  An important distinction to note is that instruction memory accesses are tightly coupled to the control flow graph in contrast to data memory accesses. This isomorphic property means the set of UCBs corresponding to data memory accesses changes more frequently thereby mandating the UCB computation at the instruction level.
\subsection {Limited Preemption Scheduling}\label{sec:lp_related_work}
The motivation for limited preemption scheduling approaches stems from limitations of fully preemptive and non-preemptive scheduling.  Fully preemptive scheduling suffers from schedulability degradation due to increased preemption overhead penalties of which CRPD comprises a significant portion.  Non-preemptive scheduling suffers from reduced system utilization due to the blocking imposed on high priority jobs.  These factors have motivated research on alternative limited preemption scheduling approaches with the goal of achieving higher task utilization and reduced preemption overhead.

One such approach is known as the deferred preemption model.  The idea behind the deferred preemption model is to permit a currently executing job to execute non-preemptively for some period of time after the arrival of a high priority job.  Two distinct models of deferred preemption have been proposed by Burns~\cite{burns:05} and Baruah~\cite{baruah:05} known as fixed preemption point model and floating preemption point model respectively.

In the floating preemption point model~\cite{baruah:05}, the beginning of non-preemptive regions occur with the arrival of a higher priority job.  The currently executing job continues executing non-preemptively for \begin{math}Q_{i}\end{math} time units or earlier if the job completes execution. The location of the non-preemptive regions is nondeterministic or essentially floating. Baruah`s~\cite{baruah:05} approach computes the maximum amount of blocking time denoted \begin{math}Q_{i}\end{math} for which a task \begin{math}\tau_{i}\end{math} may execute non-preemptively while still preserving scheduling feasibility.

Another limited preemption scheduling technique known as preemption threshold scheduling was proposed by Wang and Saksena~\cite{wang:99}.  In preemption threshold scheduling, each task is assigned two priority values, namely, a nominal static priority \begin{math}p_{i}\end{math} and a preemption threshold \begin{math}\Pi_{i}\end{math}.  A task will be preempted only if the preempting task has a nominal priority \begin{math}p_{k}\end{math} greater than the preemption threshold \begin{math}\Pi_{i}\end{math}. In the fixed preemption point model~\cite{burns:05}, a task can be preempted only at a limited set of pre-defined locations. Basically, tasks contain a series of non-preemptive regions.  Preemptions are permitted at non-preemptive region boundaries or fixed preemption points.
\newline
\indent
Two closely related derivative works implementing a fixed preemption point model for a fixed priority (FP) scheduler were proposed by Simonson and Patel~\cite{simonson:95} and by Lee et. al.~\cite{lee:98} whose objective was to reduce preemption overhead.  Simonson’s and Patel’s approach~\cite{simonson:95}, tasks are sub-divided into distinct non-overlapping intervals, each constrained by the maximum blocking time \begin{math}Q_{i}\end{math} that higher priority tasks may be subjected to while preserving task set schedulability.  At a location within each interval containing the minimum number of UCBs, a single preemption point is placed.  Lee et. al.~\cite{lee:98} adopted a different method whereby the locations of preemption points are commensurate with the cardinality of the useful cache block set less than a pre-determined threshold.   While both techniques serve to improve preemption overhead over the fully preemptive approach, their heuristic nature is unable to achieve a globally optimal solution.
\newline
\indent
In contrast, Bertogna et. al.~\cite{bertogna:10} achieved an optimal preemption point placement algorithm with quadratic time complexity.  The analysis assumed a pessimistic fixed constant context switch cost at each preemption point equal to the largest preemption overhead experienced by a task.  Later work by Bertogna et. al.~\cite{bertogna:11} relaxes the fixed constant context switch assumption using more accurate variable preemption overhead cost information via available timing analysis tools.
\newline
\indent
Our work improves these results by computing the cache related preemption delay (CRPD) contribution to the variable preemption overhead cost as a function of the current and next selected preemption points.  Our method not only accounts for the cache blocks evicted due to preemption, but also accounts for the cache blocks that are reloaded during execution between preemption points thereby improving the accuracy of marginal CRPD computations for multiple nested preemptions.
\newline
\indent
Due to the variability in CRPD and preemption overhead cost, we propose a dynamic programming algorithm to realize a globally optimal preemption point placement that further minimizes the number of preemptions and the preemption overhead cost due to the increased CRPD accuracy.
%The dynamic programming algorithm assumes a linear basic block structure with high level programming language %constructs fully contained within the basic block.
The need to subsume higher level programming constructs being the prominent assumption of the linear basic block structure can potentially diminish the utility of our approach if the non-preemptive execution time of any basic block violates the constraint \begin{math}C_{i}^{NP}\end{math} \begin{math}>\end{math} \begin{math}Q_{i}\end{math}.
%To overcome this limitation in future work, we plan to relax the linear basic block structure assumption and %address arbitrarily connected basic block structures.
